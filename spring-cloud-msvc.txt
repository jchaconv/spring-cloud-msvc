
Repos del curso:

https://github.com/in28minutes/spring-microservices/tree/master/02.restful-web-services
https://github.com/in28minutes/spring-microservices/tree/master/03.microservices


Mi repo:

https://github.com/jchaconv/spring-cloud-msvc


Web Service: Software system design to support
1*interoperable(otras aplicaciones se pueden comunicar con el ws sin importar las tecnologías en las que estén desarrolladas)
2*machine-to-machine(or application-to-application) 3*interaction over a network(para ser un ws debe poder ser invocado desde otro lugar).

Service definition:
Estructura y formato(XML o JSON) de request y response
Url expuesta para invocación o endpoints

Transport:
- Http (over the internet)
- MQ (over a queue)

SOAP (Simple object access protocol) :
* Es un formato de XML

- Specific way of building ws
- Solo usa XML
- Define la estructura de request y response en SOAP-Header y SOAP-Body (ambos contenidos en un SOAP-Envelope)
- Puede comunicarse mediante HTTP o MQ

- Service definition mediante WSDL (Web service defiinition language)
   -> Contiene endpoint, operations, request/response structure  

REST (REpresentational state transfer) :
* Es un "architectural style"

- Utiliza los conceptos presentes en HTTP
- Request usa los métodos de http(get, post, put, etc)
- Response incluye los códigos http(200, 404, 500, etc)
- Los recursos(aquello que se quiere exponer en el ws) tienen URI(uniform resource identifier)
  y pueden tener representaciones en xml, json(popular), html
- Solo HTTP 
- Para el service definition no hay un standard. WADL, SWAGGER son conocidos


Evitar las versiones SNAPSHOT
version: 3.0.0(M4) -> java17 o superior
mejor usar 2.x.x (2.7.16)
groupid: com.rest.webservices
artifactid: restful-web-services

dependencies: springweb, jpa, h2, devtools(optional)

hacer HelloWorldController
* GetMapping:
    - de un string
    - de un obj que tenga campo message (retorna json porque el @ResponseBody incluido
      en @RestContoller)

Si se quiere agregar debug logging poner esto en properties:
logging.level.org.springframework=debug

El DispatcherServlet es el componente autoconfigurado que recibe las peticiones y las trata
en su respectivo controller. 

PathVariable:

/v1/{name}
@PathVariable String name
String.format("Hello World, %s", name)


Social Media Application Rest API:

Users y Posts api's

- Crear beans : User
- Crear dao: UserDao -> retorna lista static, aún no se usa JPA/Hibernate
- En el UserController crear los métodos para findAll, findById, save


te voy a enseñar cómo obtener un usuario mediante su id en un api rest


http://localhost:8080/api/v1/users

{
    "name": "Rut",
    "birthDate": "1992-11-06"
}


200 success
201 created
204 no content
401 unauthorized
400 bad request
404 resource not found
500 Server error

Response status 201 para el save
- return ResponseEntity.created(null).build(); -> dejar el location como null, cambiar
  para ver el detalle(Location) del obj creado en Response headers

- findById con return null en el dao y exception en el controller
  Es importante el @ResponseStatus en el exception para q retorne el statusCode esperado


Generic Exception(para personalizar el body response de un error):
- Crear ErrorDetails

Solo con el UserNotFoundException tenía esta estructura el response:

{
    "timestamp": "2023-09-22T15:50:14.599+00:00",
    "status": 404,
    "error": "Not Found",
    "path": "/api/v1/users/211"
}

Luego de agregar la clase CustomizedResponseEntityExceptionHandler donde se usa:
 
- @ControllerAdvice
- extends ResponseEntityExceptionHandler 
- @ExceptionHandler(UserNotFoundException.class)

Se ve así(con el body que definimos en ErrorDetails):

{
    "timestamp": "2023-09-22T11:07:35.5043472",
    "message": "id: 99",
    "details": "uri=/api/v1/users/99"
}


DELETE:
- deleteById en el dao y controller
Las pruebas salieron bien

-------------------------------------------------------------------------------


Validations rest api:
- Agregar la dependency de validación y actualizar mvn, copiar y pegar la del starter
- Agregar @Valid de Jakarta en el PostMapping del controller (lo que hace es evaluar las validaciones del objeto Request)
- Agregar @Past @Size a los campos de User. Mostrar las demás validaciones existentes(abrir ubicación de la clase)

-> en las pruebas retorna 400 Bad Request PERO SIN BODY

- Agregar messages en las validaciones de la clase User
- Para personalizar hacer un override de handleMethodArgumentNotValid en CustomizedResponseEntityExceptionHandler
- Reemplazar el getMessage por getFieldError para q solo retorne el mensaje personalizado y no toda la traza. Objects.requireNonNull
  fue agregado para quitar el warning. Aquí también se puede concatear el ex.getErrorCount para un detalle más personalizado en el message.

- El response salió así:
{
    "timestamp": "2023-09-22T11:53:40.3956405",
    "message": "Name should have at least 3 characters",
    "details": "uri=/api/v1/users"
}


-------------------------------------------------------------------------------

* Rest Api Documentation

Para entender los resources, actions y req/resp structure (validations)
Retos para la documentacion: actualizada, correcta y consistente.
Lo mejor es hacerla desde el código y no mantenerla manualmente.

Swagger y OpenAPI

- googlear springdoc openapi, también abrir el enlace de github (springdoc-openapi-v1)
- Añadir dependency en el pom. Version 1.7.0 para springboot 2.x.x
- Ver:
  http://localhost:8080/swagger-ui.html
  http://localhost:8080/v3/api-docs

-------------------------------------------------------------------------------

* Content Negotiation
Mediante el uso de headers se establece si espera format XML o JSON.
Escoger entre diferentes lenguajes.

- Agregar dependency de jackson, reiniciar y probar
- Añadir en headers: Accept -> application/xml


-------------------------------------------------------------------------------


* Internationalization i18n

en English
nl Dutch
fr French
de Deutsch

- Crear messages.properties en resources
- En HelloWorldController agregar:
    + MessageSource y constructor
    + Método getMessageInternationalized()
- Crear messages_fr.properties e ir modificando según corresponda.
- Probar agregando: Accept-Language -> fr


-------------------------------------------------------------------------------


* Versioning Rest API
Es mejor el versionamiento si se va a cambiar la estructura del response
para no impactar a los consumers. Es la mejor práctica el versionamiento
que el cambio en producción.
- VersioningPersonController
- Opciones para el versioning:
 + URI versioning
    -http://localhost:8080/v1/person
    -http://localhost:8080/v2/person
 + Request Parameter versioning
    -http://localhost:8080/person?version=1
    -http://localhost:8080/person?version=2
 + (Custom) headers versioning:
    -http://localhost:8080/person (X-API-VERSION=1)
    -http://localhost:8080/person (X-API-VERSION=2)
 + Media Type versioning (a.k.a "content negotiation" or "accept header")
    (methods: getFirstVersionOfPersonAcceptHeader and getSecondVersionOfPersonAcceptHeader)
    (use the header accept)
    -SAME-URL produces=application/my.own.app-v1+json
    -SAME-URL produces=application/my.own.app-v2+json

-------------------------------------------------------------------------------

* HATEOAS (Hypermedia as the engine of application state)
to create links between api's

- Agregar dependency en el pom
- UserController getUserById, se generó link para allUsers con las clases:
EntityModel y WebMvcLinkBuilder

http://localhost:8080/api/v1/users/1

{
    "id": 1,
    "name": "Julio",
    "birthDate": "1995-12-12",
    "_links": {
        "all-users": {
            "href": "http://localhost:8080/api/v1/users"
        }
    }
}

-------------------------------------------------------------------------------

* Implementing Static Filtering for REST API

- Serialization: Convert object to STREAM (ex: list to JSON)
  Serialization in Java with JACKSON

- Customize field names in response. En la clase User:
    @JsonProperty("user_name")
    private String name;
  Ahora el response se ve así:
  {
      "id": 1,
      "birthDate": "1995-12-12",
      "user_name": "Julio",  <---------
      "_links": {
          "all-users": {
              "href": "http://localhost:8080/api/v1/users"
          }
      }
  }

- Return only selected fields:
    (FilteringController y SomeBean)
    -Static filtering:
        @JsonIgnoreProperties (uno o más) y @JsonIgnore (uno)
        para que no retorne campo(s)
    -Dynamic filtering:
        *Para que usando el mismo bean se pueda manejar diferente lógica de filtering
        en las api's. Se tiene que manejar en el Controller con MappingJacksonValue y
        en el bean se define el nombre del filter con @JsonFilter. Me parece mucha lógica
        y nada práctico.

        *Por ahora he visto que se tiene que agregar el mismo filtering a ambos métodos(por confirmar
        si se puede usar solo en el que sea necesario porque así no me gusta)


-------------------------------------------------------------------------------

* Monitoring APIs with Spring Boot Actuator

Monitoring and manage application in production. Endpoints:
-beans
-health
-metrics
-mappings
-etc...

Se agrega dependency al pom.xml
invocar(hay links a otras api's): http://localhost:8080/actuator

Para exponer todas las api's de actuator agregar en properties:

management.endpoints.web.exposure.include=*

En el endpoint beans están todas las clases y dependencias.

-------------------------------------------------------------------------------

* Exploring APIs with Spring Boot HAL Explorer

HAL(Json Hypertext Application Language)
Es un formato que provee links entre los recursos del API

"all-users" en "_links" en Hateoas usa el formato HAL

HAL Explorer es un API que ayuda a explorar las API's

Esto permite que las personas "non-technical" de mi equipo puedan
tener la info de las api's de una manera amigable


- Agregar dependency en el pom.xml
- Ingresar a localhost:8080
    Edit headers: /actuator      -> click en GO

/api/v1/users/1      -> se muestra el link amigable porque reconoce el formato HAL

-------------------------------------------------------------------------------


****************************************
 * Inicio - JPA and HIBERNATE section *
****************************************

Config del proyecto 02-jpa-hibernate

version: 2.7.16
groupid: com.mcsv.restful
artifactid: jpa-hibernate

Dependencies:

-Spring web
-Spring Data JDBC
-Spring Data JPA
-H2 Database

-------------------------------------------------------------------------------

* Launching up H2 Console and Creating Course Table in H2

- Agregar en properties:
    spring.h2.console.enabled=true

- Ir a localhost:8080/h2-console
- Buscar en el log de la consola la url dinámica y ponerlo en JDBC Url:
    jdbc:h2:mem:07315379-f12d-42ab-8418-3bbaf86abffb

- Agregar en properties ara establecer como estática la url:
    spring.datasource.url=jdbc:h2:mem:testdb

- Para tener tablas en la db agregar en resources schema.sql
    En la consola H2 ejecutar: SELECT * FROM COURSE;

-------------------------------------------------------------------------------

* SPRING JDBC *

Se apoya en el uso de queries(puede crecer descomunalmente, ver JdbcRepository)
y provee de métodos mediante JdbcTemplate para ejecutar dichos queries.


INSERT INTO COURSE (id, name, author)
VALUES(1, 'Lear AWS', 'in28minutes');

SELECT * FROM COURSE;

DELETE FROM COURSE WHERE id=1;

JDBC: write a lot of queries and a lot of java code
Spring JDBC: write a lot of queries but lesser java code

(Atención con las anotaciones!)

- Se crea un ejemplo con Spring JDBC -> JdbcRepository

.update() para sentencias: INSERT, UPDATE or DELETE

- Se crea JdbcCommandLineRunner para usar el método run y ejecutar
el insert del Repository. (Se usó CommandLineRunner para ejecutar código
"aislado" al levantar la aplicación).

En la consola h2 ejecutar un select * from course y se ve el registro añadido desde la aplicación.

- Se agregó el método insertDynamic y deleteDynamic en JdbcRepository para usar un query dinámico y pasarle los valores
mediante un objeto java.

- Para retornar data de la base de datos selectDynamic() en el repository
queryForObject trae un ResultSet de la bd y lo transforma al bean mediante un rowMapper

-------------------------------------------------------------------------------

* JPA *
Mapea el java bean to the table. Se usará EntityManager.
Do not worry about queries, just map entities to tables!

- Se modificó Course, usar los imports de jakarta
- CourseJpaRepository:
    - Se pudo usar @Autowired pero @PersistenceContext es más específica
    - Usar @Transactional por las operaciones que se están realizando
    - se usan los métodos apropiados de EntityManager y ya no nos preocupamos por los queries
    - se usa merge() para agregar Course
    - find() y el parámetro para la búsqueda
    - remove() para el delete
    - En CourseCommandLineRunner se comentó toda la impl de JDBC
    - Agregar en properties: spring.jpa.show-sql=true para ver los queries ejecutados en la consola

Es más sencillo que usar JDBC, entonces para qué Spring Data JPA?

-------------------------------------------------------------------------------

* SPRING DATA JPA *
- Hace más sencillo el uso de JPA
- Don't worry about EntityManager, spring will take care of everything
- Se creó CourseSpringDataJpaRepository y extiende de JpaRepository y esta clase del package spring.data hace toda la "magia"
- Se editó el CommandLineRunner
- Se crea mucho menos código, solo se necesita crear la interfaz que extienda de JpaRepository
- La ventaja que da es que se puede cambiar de base de datos con cambios en el .properties

-Se pueden usar varios métodos de spring data
-Se puede crear un método personalizado pero debe mantener la convención de nombre
para que spring data haga el query automáticamente. Ej: findByAuthor


* HIBERNATE VS JPA *

JPA: Es el API, como una interfaz
jakarta.persistenca.Entity
jakarta.persistenca.Id
- Cómo se definen los entities, con @Entity
- Cómo se mapean los atributos, con @Id, @Column

Hibernate: Es la implementación más popular de JPA
Para usar Hibernate directamente en el proyecto se pueden usar
las anotaciones como esta:
org.hibernate.annotations.Entity
(esto se dijo en el video pero veo que está deprecated)

-------------------------------------------------------------------------------

* Using JPA and HIBERNATE *

Volviendo al proyecto 01-restful:

- Añadir en properties:
    spring.h2.console.enabled=true
- Agregar las anotaciones de jakarta en User
- Configure static h2 url en properties:
    spring.datasource.url=jdbc:h2:mem:testdb

- Ejecutar: SELECT * FROM USER_DETAILS;
- Crear en /resources/data.sql
- Añadir en properties:
    spring.jpa.defer-datasource-initialization=true
    (para retrasar la inicialización del datasource y se ejecute el script
    en el archivo data.sql)


- Crear UserRepository, UserJpaController. Se probaron los métodos en postman, funcionan bien.
(Si me dejó crear user incluso con el nombre del campo cambiado a user_name)

-------------------------------------------------------------------------------

* Creating Post Entity with Many to One Relationship with User Entity *

- Crear clase Post
- @OneToMany en la clase User y el mappedBy para hacer match con la relación en la clase Post
específicamente en el atributo user. Por eso el mappedBy es "user"
- @ManyToOne en la clase Post y no agregamos mappedBy y @JsonIgnore.
    fetch: EAGER(todo junto), LAZY(no quiero toda la info)
- Agregamos @JsonIgnore en User para no mostrar en el response la lista de posts.
- Agregar en properties:
    (para mostrar los queries que se ejecutan)
    spring.jpa.show-sql=true

- Agregar inserts en post en data.sql

Hasta aquí se pudo establecer la relación entre las tablas User y Post

-------------------------------------------------------------------------------

API's para información de Post entity

- Se agregaron api's en UserJpaController
- Se creó el PostRepository

-------------------------------------------------------------------------------

* Connecting to MYSQL database *

1.- Ejecutar comandos:

docker run -d --name mysql-container -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password -e MYSQL_DATABASE=social-media-database mysql:latest

En cmd se puede entrar así:
docker exec -it mysql-container /bin/bash
bash-4.4# mysql -u root -p
Enter password:
    mysql>

use social-media-database;
select * from user_details;
select * from post;


2.- Agregar en properties:
(comentar la url de h2)

spring.datasource.url=jdbc:mysql://localhost:3306/social-media-database?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true
spring.datasource.username=root
spring.datasource.password=password

spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect


3.- Editar pom.xml, comentar la dependency de H2 y agregar:

<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>8.0.27</version>
</dependency>

Con estas configuraciones probé las api's y funcionaron bien

-------------------------------------------------------------------------------

* Implementing Basic Authentication with Spring Security *

- Agregar dependency:
<dependency>
    <groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-security</artifactId>
</dependency>

- Reiniciar app y cuando invoque en el navegador a cualquier api
me saldrá el login simple.
user: user
password está en la consola

-Agregar en properties para cambiar las credenciales:
spring.security.user.name=jchaconv
spring.security.user.password=miespositaloquita

* Enhancing Spring Security Configuration for Basic Authentication *

Spring Security usa
    Filter Chains
        - Todos los requests autenticados
        - Si un request no está autenticado se muestra una página
        - CSRF -> POST, PUT


- Crear la clase SpringSecurityConfiguration
Se mapean los 3 pasos que se usan en los filters de spring security
para el basic authentication.


-------------------------------------------------------------------------------

* MICROSERVICES *

Microservice architectural style is an approach to
developing a single application as a suite of small
services, each running in its own process and communicating
with lightweight mechanisms, often an HTTP resource API

These services are built around business capabilities and
independently deployable by fully automated deployment machinery

Small autonomous service that work together.

- rest
- Cloud enable: multiple instances si se tiene mayor carga.

Retos de los microservicios:
-Establecer límites en el desarrollo: Se va dando en el desarrollo,
ningún diseño es perfecto a la primera
-Visibility and monitoring:
    * Zipkin distributed tracing
    * Netflix API Gateway
- Dynamic scale up and down
    * Naming Server (Eureka)
    * Ribbon (Client Side Load Balancing) -> Fue reemplazado por Spring Cloud Load Balancer
    * Feign (Easier Rest Clients)
- Fault Tolerance
    * Hystrix -> Reemplazado por Resilience4j

Benefits of microservices:
* New technology and process adaption
* Dynamic scaling
* Faster release cycles

Tener en cuenta los ports para los diferentes servicios que se usarán:

https://github.com/in28minutes/spring-microservices/tree/master/03.microservices

-------------------------------------------------------------------------------

* MICROSERVICES WITH SPRING CLOUD *

Important changes:

- Spring Cloud Load Balancer instead of Ribbon
- Spring Cloud Gateway instead of Zuul
- Resilience4j instead of Hystrix

Docker to containerize the microservices and Kubernetes to orchestrate all of the microservices.

-------------------------------------------------------------------------------

* Limits microservice *

spring initializr
(solo están las versiones 3.x.x y java 17, se tiene que cambiar manualmente en el pom)
(tuve que actualizar la versión de spring cloud a 2021.0.8 para que sea compatible con spring boot 2.x.x)

version: 2.7.16
groupid: com.neoris.mcsvc
artifactid: limits-service

dependencies:
-springweb
-devtools
-actuator
-config client


- Agregar en properties:
(Esta config es necesaria por tener el import de Config Client)
spring.config.import=configserver:http://localhost:8888


- Crear LimitsController y agregar en properties para tomar los valores de aquí:
limits-service.minumum=2
limits-service.maximum=998

-------------------------------------------------------------------------------

*  Setting up Spring Cloud Config Server *

(Cambiar manualmente las versiones)
spring initializr
version: 2.7.16
groupid: com.neoris.mcsvc
artifactid: spring-cloud-config-server

spring-cloud.version: 2021.0.8

dependencies:
-devtools
-config server

- Agregar en properties:
spring.application.name=spring-cloud-config-server
server.port=8888

Agregar en el archivo limits-service.properties:
limits-service.minumum=4
limits-service.maximum=996

- En 04-spring-cloud-config-server en el archivo properties:
spring.cloud.config.server.git.uri=file:///D:/cursos-udemy/spring-cloud-msvc/git-localconfig-repo

Y la anotación @EnableConfigServer en la clase principal(SpringCloudConfigServerApplication.java)

- Ingresar a localhost:8888/limits-service/default
Retorna un json. Con esto ya tenemos centralizada la configuracion

-------------------------------------------------------------------------------

* Connect Limits Service to Spring Cloud Config Server *

En 03-limits-service agregar:
spring.application.name=limits-service

Ya tenía la otra llave que referencia al config-server
con este cambio al invocar al api llama a los valores del properties local
del server

-------------------------------------------------------------------------------

* Configuring Profiles for limits-service *

en el repo local se agregan archivos con -dev -qa
Ir a localhost:8888/limits-service/dev ir retornará la config de dev y default

Si quiero dejar uno activo agregar en properties:
spring.profiles.active=dev
spring.cloud.config.profile=dev

Debería salir esto:
c.n.m.l.LimitsServiceApplication         : The following 1 profile is active: "dev"

Se pueden crear muchos properties, incluso de diferentes microservicios y esa es la ventaja
de tener todo centralizado.

-------------------------------------------------------------------------------

*  Setting up currency-exchange-service *
(Cambiar manualmente las versiones)
(Tener en cuenta que para usar registrar en Zipkin se actualizaron las versiones)
spring initializr
version: 2.7.16
groupid: com.neoris.mcsvc
artifactid: currency-exchange-service

spring-cloud.version: 2021.0.8

dependencies:
-web
-config client
-actuator

- Agregar en properties:
spring.config.import=optional:configserver:http://localhost:8888
spring.application.name=currency-exchange
server.port=8000


Currency Exchange Service:
http://localhost:8000/currency-exchange/from/USD/to/PER

Response structure:
{
   "id":10001,
   "from":"USD",
   "to":"INR",
   "conversionMultiple":65.00,
   "environment":"8000 instance-id"
}

-------------------------------------------------------------------------------

* Setting up Dynamic Port in the Response *

Se agrega la clase Environment en CurrencyExchangeController getExchangeValue() para obtener el port y retornarlo en el response.

Hay una opción en eclipse para tener dos instancias de la aplicación en puertos diferentes. Cuando hizo esa prueba se ve que el puerto
en el response también cambia. Con esto se tiene identificado cuál instancia se está usando.

-------------------------------------------------------------------------------

* Configure JPA and Initialized Data *

- Se agregaron las dependencias:

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-jpa</artifactId>
</dependency>

<dependency>
    <groupId>com.h2database</groupId>
	<artifactId>h2</artifactId>
	<scope>runtime</scope>
</dependency>

- Agregar en properties:

spring.h2.console.enabled=true
spring.datasource.url=jdbc:h2:mem:testdb
spring.jpa.show-sql=true

- Mapear como Entity la clase CurrencyExchange
Se cambió el nombre de los campos para las tablas con @Column para evitar conflictos con SQL
Hasta aquí ya fue creada la tabla y se puede ver en:
http://localhost:8000/h2-console

- Crear resources/data.sql para insertar datos en la tabla.

- Debido a que en estas versiones de spring boot la data se inserta antes que se creen las tablas
se necesita agregar en properties:
spring.jpa.defer-datasource-initialization=true

Con este cambio ya se ve la tabla con los datos correspondientes.

- Se crea CurrencyExchangeRepository y un método custom. Luego se agrega al controller.
Hasta aquí se muestra la info de la bd correctamente en el api.

-------------------------------------------------------------------------------

*  Setting up currency-conversion-service *
(Cambiar manualmente las versiones)
spring initializr
version: 2.7.16
groupid: com.neoris.mcsvc
artifactid: currency-conversion-service

spring-cloud.version: 2021.0.8

dependencies:
-web
-config client
-actuator

- Agregar en properties:
spring.config.import=optional:configserver:http://localhost:8888
spring.application.name=currency-conversion
server.port=8100


Currency Conversion Service:
http://localhost:8100/currency-conversion/from/USD/to/PER/quantity/10

Response structure:

{
  "id": 10001,
  "from": "USD",
  "to": "INR",
  "conversionMultiple": 65.00,
  "quantity": 10,
  "totalCalculatedAmount": 650.00,
  "environment": "8000 instance-id"
}

- Crear CurrencyConversionController se pone data en duro en el método calculateCurrencyConversion()

- Para llamar a currency-exchange-service se usa RestTemplate en calculateCurrencyConversion()
El nuevo response queda de esta manera:
{
    "id": 10001,
    "from": "USD",
    "to": "PER",
    "quantity": 3.75,
    "conversionMultiple": 10,
    "totalCalculatedAmount": 37.50,
    "environment": "8000"
}

-------------------------------------------------------------------------------

* Using Feign REST Client for Service Invocation *

Para no tener que repetir todo el código del ejemplo anterior se usa FEIGN, un framework provisto por Spring Cloud
para la comunicación entre microservicios.

- Agregar dependency:
<dependency>
    <groupId>org.springframework.cloud</groupId>
	<artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>

- Agregar @EnableFeignClients en la clase principal

- Crear CurrencyExchangeProxy. Poner el nombre del mcsvc a invocar en @FeignClient

Tomar el "encabezado" del método del Controller del otro servicio
y poner como objeto de response nuestro Entity ya que será mapeado por spring automáticamente con los campos que hagan match.
Ya no se usa todo el path sino solo la uri necesaria.


- En CurrencyConversionController se crea un nuevo método que use el proxy y se reduce el código a una línea.

Todas las pruebas salieron bien hasta aquí

-------------------------------------------------------------------------------

* Understand Naming Server and Setting up Eureka Naming Server *

Como en CurrencyExchangeProxy se tiene hardcodeado localhost:8000 y surge la necesidad de tener varias instancias del microservicio
es necesario crear un NamingServer que actúe como un loadBalancer para todas las instancias del mcsvc

(Cambiar manualmente las versiones)
spring initializr
version: 2.7.16
groupid: com.neoris.mcsvc
artifactid: naming-server

spring-cloud.version: 2021.0.8

dependencies:
-eureka server
-devtools
-actuator

- Agregar @EnableEurekaServer en la clase principal

- Agregar en properties:

spring.application.name=naming-server
server.port=8761

#Eureka recommendations:
eureka.client.register-with-eureka=false
eureka.client.fetch-registry=false

#For debugging
#eureka.instance.prefer-ip-address=true
#eureka.instance.hostname=localhost

- Ingresar a http://localhost:8761/ y se carga el home de nuestro server

- Agregar la dependency de eureka-client en los mcsvc currency-exchange y currency-conversion para registrarlos en el server:

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>

- Agregar en properties de ambos mcsvc:

eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka

Hasta aquí hemos registrado nuestros dos mcsvc en eureka-server

-------------------------------------------------------------------------------

* Load Balancing with Eureka, Feign & Spring Cloud LoadBalancer *

- Quitar el port de CurrencyExchangeProxy para que al conectarse con el naming-server se haga el load-balancing
con las instancias activas de currency-exchange

- NO pude levantar otra instancia del servicio currency-exchange en un port distinto.
Sin embargo, el load-balancing es automático y viene gracias a eureka-server.
Se puede probar haciendo requests y se ve que ambas insntacias responden. También se puede probar
dando de baja a una instancia y levantando otra.

-------------------------------------------------------------------------------

* Setting up Spring Cloud API Gateway *

- Efectivo para ruteo de API's
- Provee security y monitoring/metrics
- Trabaja con Spring webflux

+ Features:

- se puede hacer match de las rutas con cualquier atributo del request(header, param, etc)
- se pueden definir predicates y filters
- integración con spring cloud discovery client (load balancing)
- path rewriting



How we can proxy through the API Gateway to other microservices using Eureka

Para implementar todas las features comunes entre microservicios (logging, authorization, authentication, etc)

Actualmente: Spring Cloud API Gateway
Antes: Zuul


(Cambiar manualmente las versiones)
spring initializr
version: 3.2.1
groupid: com.neoris.mcsvc
artifactid: api-gateway

java.version: 17  -> Tuve que usar este jdk por conflictos con la dependencia del Gateway
spring-cloud.version: 2023.0.0


Dependencies:
- devtools (opcional, gasta mucha memoria)
- actuator
- Eureka discovery client
- Gateway (Spring Cloud Routing)
- eureka client

- Agregar en properties:

spring.application.name=api-gateway
server.port=8765

eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka (se agrega para que al entrar a localhost:8761 
aparezca el API GATEWAY registrado en el server de EUREKA)

spring.cloud.gateway.discovery.locator.enabled=true
spring.config.import=optional:configserver:http://localhost:8888
spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true


Y luego invocar:

http://localhost:8765/currency-exchange/currency-exchange/from/EUR/to/PER
http://localhost:8765/currency-conversion/currency-conversion/from/USD/to/PER/quantity/10


Los responses son correctos 

-------------------------------------------------------------------------------

* Exploring Routes with Spring Cloud Gateway *

- Crear ApiGatewayConfiguration.java

Con la config inicial se puede invocar a http://localhost:8765/get y responde correctamente
Ver los comentarios en el desarrollo para ver las funcionalidades.

Con los routes configurados se puede invocar a los mcsvc con las uris:

http://localhost:8765/currency-exchange/from/EUR/to/PER
http://localhost:8765/currency-conversion/from/USD/to/PER/quantity/10
http://localhost:8765/currency-conversion-feign/from/USD/to/PER/quantity/10

http://localhost:8765/currency-conversion-new/from/USD/to/PER/quantity/10


-------------------------------------------------------------------------------


* Implementing Spring Cloud Gateway Logging Filter *

(para ver los logs de los requests realizados)
Se crea la clase LoggingFilter. Al hacer request al api-gateway se ve en los logs de la consola algo como esto:

[ctor-http-nio-3] c.n.m.apigateway.filter.LoggingFilter    : Path of the request received -> /currency-conversion-feign/from/USD/to/PER/quantity/10
[ctor-http-nio-3] c.n.m.apigateway.filter.LoggingFilter    : Path of the request received -> /currency-exchange/from/EUR/to/PER
[ctor-http-nio-3] c.n.m.apigateway.filter.LoggingFilter    : Path of the request received -> /currency-conversion-feign/from/USD/to/PER/quantity/10



-------------------------------------------------------------------------------

* Getting started with Circuit Breaker - Resilience4j *
(tener en cuenta que el ejemplo compila bien pero no funciona porque no es compatible con spring boot 3
hay conflicto de versiones y no pude resolverlo todavía)

- Se crea CircuitBreakerController para probar un api que falle

@Retry(name = "sample-api") -> hace 3 request en caso de error(según el vídeo, yo intenté y solo ejecutó 1 vez)
se agregó método callback en el api
para configurar el número de reintentos agregar en properties:
(debe tener en la llave el nombre que puse en @Retry)

resilience4j.retry.instances.sample-api.maxAttempts=5

-------------------------------------------------------------------------------

* Circuit Breaker Features of Resilience4j *

Se comenta la línea del @Retry y se agrega:

@CircuitBreaker(name = "default", fallbackMethod = "hardcodedResponse")

Sirve para que en caso falle el mcsvc se llame al método fallback y no al método real una y otra vez.
La mejor feature es que no hace requests innecesarios porque revisa al interno si el servicio está operativo,
si no lo está hace pocas peticiones.


* Exploring Rate Limiting and BulkHead Features of Resilience4j *

Comentar la anotación @CircuitBreaker y agregar:

@RateLimiter(name = "default")

Agregar en properties:

#2 requests es el límite establecido
resilience4j.ratelimiter.instances.default.limitForPeriod=2

#10s es el tiempo en el que se permite la cantidad de requests
resilience4j.ratelimiter.instances.default.limitRefreshPeriod=10s

También se puede usar @Bulkhead para establecer el número máximo de peticiones

-------------------------------------------------------------------------------

* Distributed Tracing *

Para tener mejor visibilidad de los errores generados en la cadena de comunicación entre mcsvc

Todos los mcsvc envían la información a un "Distributed Tracing Server" y este guarda la info en una database

Aquí es donde entra Zipkin como un Tracing Server. Vamos a conectar nuestros mcsvc con Zipkin al levantarlo en un docker container.

* Launching Zipkin Container using Docker *

docker run -p 9411:9411 openzipkin/zipkin:2.23

Entrar a localhost:9411 y carga el home del servidor. Falta conectar los mcsvc para ver la traza

-------------------------------------------------------------------------------

* Getting Started with Observability and OpenTelemetry *

OpenTelemetry: Entiendo que es como un stack y standard de tecnologías que ayudan con Observability(tracing, logging, metrics)
ayuda porque ya no nos preocupamos por escoger una tecnología diferente para cada aspecto de metrics, logs, etc

-------------------------------------------------------------------------------


* Connecting Currency Exchange Microservice with Zipkin *

Micrometer asigna id's a cada request en los mcsvc, por eso es vital para la trazabilidad.


Se actualizaron las versiones:

spring boot: 3.0.6
java: 17
spring cloud: 2022.0.0

- Agregar dependencias:

<dependency>
	<groupId>io.micrometer</groupId>
	<artifactId>micrometer-observation</artifactId>
</dependency>

<dependency>
	<groupId>io.micrometer</groupId>
	<artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>

<dependency>
	<groupId>io.opentelemetry</groupId>
	<artifactId>opentelemetry-exporter-zipkin</artifactId>
</dependency>

- Agregar en properties:

management.tracing.sampling.probability=1.0
logging.pattern.level=%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]

- Agregar Logger en CurrencyExchangeController

Ejecutar el naming-server y luego exchange-service
Llamar al servicio y ver logs en Zipkin, todo correcto!


-------------------------------------------------------------------------------

* Connecting Currency Conversion Microservice & API Gateway with Zipkin *

Se hizo lo mismo que en el mcsvc anterior pero debido al uso de FEIGN en currency-conversion se agregó la dependencia:

<dependency>
	<groupId>io.github.openfeign</groupId>
	<artifactId>feign-micrometer</artifactId>
</dependency>

Además se cambió el uso de RestTemplate en el CurrencyConversionController para que pueda ser registrado por micrometer.
Básicamente se agregó una clase embebida @Configuration y luego se inyectó en la principal para no hacer new RestTemplate()


Las pruebas salieron bien y se ven los logs de Zipkin



-------------------------------------------------------------------------------

* Creating Container Image for Currency Exchange Microservice *

1.- Usar el plugin de maven para buildear la imagen. Agregar en pom.xml:

<plugin>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-maven-plugin</artifactId>
	<configuration>
		<image>
			<name>jchaconv/${project.artifactId}:${project.version}</name>
		</image>
		<pullPolicy>IF_NOT_PRESENT</pullPolicy>
	</configuration>
</plugin>


2.- Luego ejecutar:
spring-boot:build-image -DskipTests

O manualmente en IntelljIDEA en las opciones de Maven
Plugins -> spring-boot -> spring-boot:build-image

Y aparece este log al final de la ejecución:
[INFO] Successfully built image 'docker.io/jchaconv/currency-exchange-service:0.0.1-SNAPSHOT'


3.- Para levantar el container:
docker run -p 8000:8000 -d jchaconv/currency-exchange-service:0.0.1-SNAPSHOT

Se obtiene el response correctamente pero se ven errores en el container porque no está levantado el naming-server

¡Detener el container para iniciarlo con docker-compose!

-------------------------------------------------------------------------------


* Getting Started with Docker Compose - Currency Exchange Microservice *

1.- Crear docker-compose.yaml

(Usar espacios para el formato y no TABS)

2.- En la ruta del archivo ejecutar el comando:

docker-compose up -d                           -> modo detach
docker-compose logs                            -> para ver logs
docker-compose logs [nombre_del_servicio]      -> logs de un servicio especifico
docker-compose down                            -> termina los containers creados 

3.- Ejecutar request del servicio.
Responde correctamente hasta aquí.



-------------------------------------------------------------------------------

* Running Eureka Naming Server with Docker Compose *

1.- Generar la image, para eso hacer lo mismo que con currency-exchange.
Agregar la config en pom.xml y ejecutar los comandos.

Se creó correctamente:
jchaconv/naming-server:0.0.1-SNAPSHOT

2.- Modificar el docker-compose.yml

(a la altura de depends_on)
environment:
  EUREKA.CLIENT.SERVICEURL.DEFAULTZONE: http://naming-server:8761/eureka

O cambiar la property de currency-exchange:
eureka.client.serviceUrl.defaultZone=http://naming-server:8761/eureka

(no hace falta borrar la imagen existente, es reemplazada automáticamente)


3.- Ejecutar el comando:
docker-compose up -d
docker-compose logs naming-server

Las pruebas fueron correctas y figura la instancia de currency-exchange en EUREKA

-------------------------------------------------------------------------------

* Running Currency Conversion Microservice with Docker Compose *

1.- Ejecutar los mismos pasos que en los mcsvc anteriores: Agregar dependencies en pom.xml,
modificar la property de eureka y generar la imagen.

2.- Se quita el localhost por currency-exchange en CurrencyConversionController

3.- Modificar docker-compose file y ejecutar el comando:
docker-compose up -d

Hasta aquí las pruebas correctas y los dos mcsvc figuran en EUREKA

(Hacer lo mismo para api-gateway: No se pudo por conflictos de versiones)

-------------------------------------------------------------------------------

* Running Zipkin with Docker Compose *

1.- Agregar cambios en docker-compose. También se agregó variable de environment para los dos mcsvc

 zipkin-server:
    image: openzipkin/zipkin:2.23
    mem_limit: 300m
    ports:
      - "9411:9411"
    networks:
      - currency-network
    restart: always #Restart if there is a problem starting up

(Si levantó el server de zipkin pero no logueó nada)


-------------------------------------------------------------------------------

* Docker, Kubernetes and Microservices - Made for each other *

Se habla de "Container Orchestration" cuando se presentan estas necesidades:

- más instancias de un container
- load balancer para distribuir la carga entre instancias de mcsvc
- autoscaling basado en la demanda
- service discovery para que los mcsvc se identifiquen unos con otros
- self healing para que las instancias que fallan sean reemplazadas automáticamente
- zero downtime deployment para pasar de una versión v1 a v2 sin tiempos de caída de la aplicación

Tecnologías que proveen "Container Orchestration":

AWS: ECS y Fargate

Cloud neutral: KUBERNETES
    Se puede usar en mi propio datacenter o en la nube:
    AWS   -> EKS
    Azure -> AKS 
    GCP   -> GKE (ofrece free tier)


Kubernetes administra los servers virtuales.
AWS los llama EC2(Elastic Compute Cloud), Azure -> virtual machines y GCP -> Compute engines
y Kubernetes usa el término NODES. 
Como se pueden administrar miles de nodes se necesita un manager para cierta cantidad de nodes.
Es por eso que:

CLUSTER contiene MASTER NODES Y WORKER NODES

(BORRAR TODO LO QUE SE CREA PARA EVITAR COBROS)

1.- Crear cuenta en GCP
https://cloud.google.com/

Figura un proyecto inicial creado por default.

---

2.- Ir a la consola y buscar Kubernetes Engine
Esperar a que todo se active

Create cluster -> name: in28minutes-cluster -> create (dejar todo lo demás por defecto)

Entrar al cluster creado y up & running, ver features y nodes

---

3.- Para hacer deploy de un mcsvc se necesita conectara con el cluster usando la shell de GCP

En la parte superior derecha buscar el botón de la consola "Activate Cloud Shell"
Se abre en el mismo navegador y se puede editar las preferencias. Dar en "Open in new window"

En el cluster hay un botón(icon) que dice CONNECT. Copiar el comando y ejecutarlo.

Ejecutar los siguientes comandos:

kubectl version

Para crear un deployment(se pone el nombre del deployment y se trae la imagen de dockerhub):
kubectl create deployment hello-world-rest-api --image=in28minutes/hello-world-rest-api:0.0.1.RELEASE

Para exponer al mundo:
kubectl expose deployment hello-world-rest-api --type=LoadBalancer --port=8080

En GCP ir a Services & Ingress -> Kubernetes Services -> Click en endpoints

Es algo como esto en el navegador:

35.223.169.37:8080/hello-world
35.223.169.37:8080/hello-world-bean

(Carga correctamente)

---

Para ver eventos:
kubectl get events


Por detrás pasa lo siguiente para que todo funcione:

Cuando Kubernetes crea un deployment se crea un replica-set, pod
y cuando se expone el deployment se crea un service

kubectl get pods
kubectl get replicasets
kubectl get deployment
kubectl get service

pod
replica-set
service


*****
POD:
*****

pod: es la unidad deployable más pequeña
tienen ip única. pueden contener múltiples containers

kubectl get pods -o wide
kubectl explain pods   -> aparece información de los conceptos

copiar el id del pod:

kubectl describe pod id-pod    -> se muestra info relevante del pod


NODE : {
    POD1: {
        CONTAINER1,
        CONTAINER2
    },
    POD2: {
        CONTAINER3,
        CONTAINER4
    }
}


*************
REPLICA-SET
*************

asegura que un número determinado de pods tengan un estado running

kubectl get replicasets
kubectl get rs

kubectl get pods -o wide    -> tomar el id-pod
kubectl delete pods id-pod
kubectl get pods -o wide -> se ve que se creó un nuevo pod automáticamente

esto hace que no haya tiempos de caída de la aplicación

Para incrementar el número:
kubectl scale deployment hello-world-rest-api --replicas=3
kubectl get pods    -> se ve que ahora hay 3 pods

cargar la url: ip-gcp:8080/hello-world varias veces y se ve que cambia el id

kubectl get replicaset    -> aparece el desired 3

para ver los eventos en orden de ejecución:

kubectl get events --sort-by=.metadata.creationTimestamp

kubectl explain replicaset   -> info del comando

********************
    DEPLOYMENT
********************

kubectl get rs -o wide    -> info relacionada con el replicaset

kubectl set image deployment hello-world-rest-api hello-world-rest-api=DUMMY_IMAGE:TEST   -> el segundo hello-world es el nombre del container y el nombre de la imagen DUMMY es incorrecto

esta actualización debería hacer que la aplicación se caiga. sin embargo, sigue funcionando correctamente.

kubectl get rs -o wide   -> ahora hay dos replicaset y se ve que el nuevo con la DUMMY_IMAGE tiene estado READY = 0 porque obviamente esta imagen no existe y tiene error

kubectl get pods  -> aquí se ve claramente ese status InvalidImageName en el cuarto pod. copiar el id-pod con error

kubectl describe pod id-pod   -> aquí se ve el log con la descripción explícita

kubectl get events --sort-by=.metadata.creationTimestamp -> aquí también se ve un poco de detalle



DEPLOYMENT : {
    REPLICA-SET-1: {    (app v1)
        POD1: {
            CONTAINER1,
            CONTAINER2
        },
        POD2: {
            CONTAINER3,
            CONTAINER4
        }
    },
    REPLICA-SET-2: {    (app v2) -> lo que intenta es levantar una instancia de la nueva versión pero ocurrió error según nuestro ejemplo
        POD1: {
            CONTAINER1,
            CONTAINER2
        },
        POD2: {
            CONTAINER3,
            CONTAINER4
        }
    }
    
}

Ahora establezco con una imagen real:

kubectl set image deployment hello-world-rest-api hello-world-rest-api=in28min/hello-world-rest-api:0.0.2.RELEASE

kubectl get pods   -> 3 pods en TERMINATING y 3 pods en RUNNING

kubectl get rs   -> Hay 3 y solo 1 que tiene READY = 3  

Si se carga el api en el navegador se ve el cambio a V2

en los eventos se ve el detalle del autoscaling para 0 downtime


********************
    SERVICES
********************

Los SERVICES hacen que no tenga que llamar a cada ip de pod sino a una sola url
provee una sola external interface. permanent address

es creado en el momento de darle expose deployment

Ir a Services & Ingress -> entrar al service -> ver la info mencionada

Buscar Load Balancing en GCP -> entrar al load balancer y ver la info, aparecen las instances


kubectl get pods -o wide    -> todos tienen una ip
kubectl delete pod pod-id
kubectl get pods -o wide    -> al hacer otra vez la consulta se ha creado un pod nuevo automatically
kubectl delete pod pod-id
kubectl get pods -o wide    -> las ip's también cambian

kubectl get services  -> se ve que está creado el loadbalancer

Para acceder al Cluster-ip se puede acceder desde adentro porque no tiene External-ip

 
*GCP*
Desde Workloads se puede editar manualmente el deployment
también se puede editar el yaml


*******************************
    KUBERNETES ARCHITECTURE
********************************

Master Node: {
    API Server: "kube-apiserver",
    Distribute Database: "etcd",
    Scheduler: "kube-scheduler",
    Controller Manager: "kube-controller-manager"
}


Installing GCLOUD -> es una consola de comandos
googlear e instalar


gcloud auth login
gcloud set project PROJECT_ID


Install kubectl:
entrar a la página de kubernetes y seguir los pasos

entrar a clusters en GCP:
copiar el comando en la opción CONNECT e ingresar el comando en la consola gcloud

---

Setup Currency Exchange & Conversion Microservices - Kubernetes

- Hacer cambios en el pom.xml:
    - cambiar version del project
    - cambiar name, al final poner "-kubernetes"
    - comentar spring-cloud-starter-config y eureka-client
    - comentar sleuth-zipkin y spring-rabbit

- En CurrencyConversionController agregar:
logger.info("...")  -> revisar en github

- En CurrencyExchangeController agregar host y version para retornarlo en el environment

- Agregar en properties:
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true

- En CurrencyExchangeProxy cambiar el @FeignClient

---

* Container images for Exchange & Currency Conversion Microservices *

Generar las imagenes con el build de maven

En la consola:
docker login
docker push [image-name]

Validar que las imagenes figuren en mi cuenta de dockerhub

---

* Deploy Microservices to Kubernetes & Understand Service Discovery *

en consola:
kubectl version
kubectl create deployment currency-exchange --image=[image-name]
kubectl expose deployment currency-exchange --type=LoadBalancer --port:8000
kubectl get svc   -> se ve el LB
kubectl get pods o get po            -> abreviaturas
kubectl get replicaset o get rs
kubectl get all

copiar el external-ip del loadBalancer

en GCP -> cloudshell:

curl http://34.66.241.150:8000/currency-exchange/from/USD/to/PER  → poner la ip correcta y validar response


exponiendo currency-conversion:

kubectl create deployment currency-conversion --image=[image-name]
kubectl expose deployment currency-conversion --type=LoadBalancer --port:8100

kubectl get svc
kubectl get svc --watch

curl http://34.67.33.185:8100/currency-conversion-feign/from/USD/to/PER/quantity/10     → response correcto en GCP

(ver environment del response, lo que sale es el id del pod)


---

* Creating Declarative Configuration Kubernetes YAML for Microservices *

En una consola en la carpeta del mcsvc:

kubectl get deployment currency-exchange -o yaml >> deployment.yaml     → se crea automáticamente el archivo
kubectl get service currency-exchange -o yaml >> service.yaml
kubectl diff -f deployment.yaml     → para ver diferencias
kubectl apply -f deployment.yaml

kubectl get pods        → validar pods creados

en gcp ejecutar comando:
watch http://34.66.241.150:8000/currency-exchange/from/USD/to/PER       → es para ejecutar curls constantemente y ver el balanceo


----

* Clean up Kubernetes YAML for Microservices *

hacer un backup del deployment.yaml
editar un nuevo archivo → ver cambios en github o video

no hizo pruebas solo explicó los cambios


----


* Enable Logging and Tracing APIs in Google Cloud Platform *

En GCP buscar: Apis and Services

Click en "Enable APIS and SERVICES"
buscar: logging → click en "Cloud Logging API"
"Manage"

buscar: Stackdriver API

parece que solo los muestra activos en su cuenta


----

* Deploying Microservices using Kubernetes YAML Configuration *

kubectl delete all -l app=currency-exchange     → con esto elimino pods, service, deployment y rs
kubectl delete all -l app=currency-conversion
kubectl get all     → debe estar vacío


kubectl apply -f deployment.yaml
kubectl get pods
kubectl get svc --watch

tomar la ext ip y hacer un watch en la consola de GCP

lo interesante es que si hago un cambio en el deployment.yaml (por ejemplo para aumentar rs) solo tengo que guardar el cambio y ejecutar el comando nuevamente:

kubectl apply -f deployment.yaml            → no hace falta borrar nada

----

*  Playing with Kubernetes Declarative YAML Configuration *

hacer backup del deployment.yaml

hacer un deployment.yaml para currency-conversion (ver cambios en github o video)

- en una consola en el directorio del mcsvc:

kubectl apply -f deployment.yaml

kubectl get svc     → se ve el LB en "pending"
kubectl get svc --watch     → esto es para mantener "viva" la ejecución del comando y ver el cambio en el resultado

- hacer un curl en GCP y validar response

----

* Creating Environment Variables to enable Microservice Communication *

- cambió la url de feign por algo más genérico, también la versión del app en pom.xml y generó nuevamente las imágenes.
- en consola: docker push image-name
- se actualizó el deployment.yaml (el nombre de imagen)
    * agregar environment variables con:
        env:
          -name: CURRENCY_EXCHANGE_URI
           value: http://currency-exchange

kubectl diff -f deployment.yaml          → se ven las diferencias en un formato feo
kubectl apply -f deployment.yaml


hacer peticiones a los servicios


----

* Understanding Centralized Configuration in Kubernetes - Config Maps *

Entiendo que sirve como una opción en lugar de variables de entorno

kubectl create configmap currency-conversion --from-literal=CURRENCY_EXCHANGE_URI=http://currency-exchange

kubectl get configmap currency-conversion

kubectl get configmap currency-conversion -o yaml

kubectl get configmap currency-conversion -o yaml >> configmap.yaml     → para que se guarde en un archivo

en metadata solo dejar el name y namespace

hacer backup del deployment.yaml

agregar en el nuevo deployment.yaml el contenido del configmap.yaml

comentar las variables de entorn en env y reemplazar por:

envFrom:
  - configMapRef:
      name: currency-conversion

kubectl apply -f deployment.yaml

kubectl logs -f pod-id

Hacer un curl al api y responde correctamente.

----

* Exploring Centralized Logging and Monitoring in GKE *

watch -n 0.1 curl http://34.66.241.150:8100/currency-conversion-feign/from/USD/to/PER/quantity/10

entrar al cluster, hacer scroll y en Features ver el button-link "View logs"

hay todo un dashboard donde se pueden ver los logs por container, pod, etc

----

* Exploring Microservices Deployments with Kubernetes *

kubectl rollout history deployment currency-conversion
kubectl rollout history deployment currency-exchange

* Autoscaling Microservices with Kubernetes *

kubectl scale deployment currency-exchange --replicas=2   → esto es manual y no es buena práctica

mejor es:

kubectl autoscale deployment currency-exchange --min=1 --max=3 --cpu-percent=5          → si es mayor de 5 % para pruebas

kubectl get hpa

kubectl get pods            → se creó un pod más con el autoscale

kubectl top pod     → lo ordena mejor
kubectl top nodes

kubectl delete hpa currency-exchange

kubectl apply -f deployment.yaml

kubectl get pods

terminar eliminando el cluster!

----

